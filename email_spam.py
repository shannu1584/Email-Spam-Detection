# -*- coding: utf-8 -*-
"""email_spam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K6Ky_Zop2CmVYBj-0uyPhXcvM3g43hke
"""

!pip install datasets transformers torch scikit-learn flask pyngrok huggingface_hub

from huggingface_hub import login
login("")

from huggingface_hub import whoami
print(whoami())

from datasets import load_dataset
import pandas as pd
dataset=load_dataset("sms_spam")

print("Dataset keys:",dataset.keys())
print("Number of examples:",len(dataset['train']))
print("\nSample data points:")
for i in range(3):
  print(f"Message{i+1}:")
  print("Text:",dataset['train'][i]['sms'])
  print("label:","spam" if dataset['train'][i]['label']==1 else "Ham")
  print("-"*40)

df=pd.DataFrame(dataset['train'])
df['label_name']=df['label'].apply(lambda x:"Spam" if x==1 else "Ham")
print("\nDataFrame head:")
print(df.head())

print(df.tail())

print(df.info)

print(df.describe())

print(df.isna())

print("\nclass distribution:")
print(df['label_name'].value_counts())

import matplotlib.pyplot as plt
plt.bar(df['label_name'].value_counts().index,df['label_name'].value_counts().values)

from sklearn.model_selection import train_test_split
train_test=dataset['train'].train_test_split(test_size=0.2,seed=42,stratify_by_column='label')
train_dataset=train_test['train']
test_dataset=train_test['test']

print("Train/Test split sizes:")
print("Train:",len(train_dataset))
print("Test:",len(test_dataset))

print("\nFirst taining sample:")
print(train_dataset[0])

from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
def tokenize_batch(batch):
  return tokenizer(batch["sms"], padding=True, truncation=True, max_length=128)
train_dataset = train_dataset.map(tokenize_batch, batched=True)
test_dataset = test_dataset.map(tokenize_batch, batched=True)
train_dataset = train_dataset.rename_column("label", "labels")
test_dataset = test_dataset.rename_column("label", "labels")
train_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])
test_dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])



!pip install evaluate

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
import evaluate
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)
metric = evaluate.load("accuracy")
def compute_metrics(eval_pred):
  logits, labels = eval_pred
  predictions = logits.argmax(axis=-1)
  return metric.compute(predictions=predictions, references=labels)

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
import evaluate

# Load model
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)

# Metric
metric = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = logits.argmax(axis=-1)
    return metric.compute(predictions=predictions, references=labels)

# ‚úÖ Training arguments - OLD compatible (no evaluation_strategy)
training_args = TrainingArguments(
    output_dir="./results",
    save_steps=500,                    # save checkpoint every 500 steps
    logging_dir="./logs",
    logging_steps=100,                 # log every 100 steps
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=2,
    weight_decay=0.01,
    report_to=[]                       # disables wandb auto logging
)

# Trainer (shows tqdm automatically)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# üöÄ Train with tqdm
trainer.train()

# ‚úÖ Evaluate manually at the end
metrics = trainer.evaluate()
print("Final evaluation metrics:", metrics)

model.push_to_hub("email_spam")
tokenizer.push_to_hub("email_spam")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# from flask import Flask, render_template, request
# from transformers import pipeline
# 
# app = Flask(__name__)
# 
# # Load pipeline from your fine-tuned model on Hugging Face
# spam_clf = pipeline("text-classification", model="shanmukha1584/email_spam")
# 
# @app.route("/", methods=["GET", "POST"])
# def home():
#     result = ""
#     message = ""
#     if request.method == "POST":
#         message = request.form.get("message", "").strip()
#         if message:
#             pred = spam_clf(message)[0]
#             label = "üö® Spam ‚ùå" if pred['label'] == "LABEL_1" else "‚úÖ Not Spam"
#             result = f"{label} (Confidence: {pred['score']:.2f})"
#     return render_template("index.html", result=result, message=message)
# 
# if __name__ == "__main__":
#     app.run(host="0.0.0.0", port=8000)

!mkdir -p templates

!mkdir -p static

# Commented out IPython magic to ensure Python compatibility.
# %%writefile templates/index.html
# <!DOCTYPE html>
# <html>
# <head>
#     <title>üìß Spam Detector</title>
#     <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
# </head>
# <body>
#     <div class="container">
#         <h1>üìß Email / SMS Spam Detector</h1>
#         <form method="post">
#             <textarea name="message" rows="5" placeholder="Enter your message here...">{{ message }}</textarea>
#             <button type="submit">Check üöÄ</button>
#         </form>
# 
#         {% if result %}
#         <div class="result">
#             <h2>{{ result }}</h2>
#         </div>
#         {% endif %}
#     </div>
# </body>
# </html>

# Commented out IPython magic to ensure Python compatibility.
# %%writefile static/style.css
# body {
#     font-family: 'Segoe UI', sans-serif;
#     background: linear-gradient(135deg, #141E30, #243B55);
#     color: #fff;
#     display: flex;
#     justify-content: center;
#     align-items: center;
#     height: 100vh;
#     margin: 0;
# }
# 
# .container {
#     text-align: center;
#     width: 50%;
#     background: rgba(255, 255, 255, 0.1);
#     padding: 30px;
#     border-radius: 16px;
#     box-shadow: 0 4px 20px rgba(0,0,0,0.5);
# }
# 
# h1 {
#     margin-bottom: 20px;
#     color: #FFD700;
# }
# 
# textarea {
#     width: 90%;
#     padding: 12px;
#     border-radius: 10px;
#     border: none;
#     outline: none;
#     font-size: 16px;
#     margin-bottom: 15px;
# }
# 
# button {
#     background: #FFD700;
#     color: #000;
#     font-weight: bold;
#     padding: 12px 20px;
#     border-radius: 8px;
#     border: none;
#     cursor: pointer;
#     transition: background 0.3s ease-in-out;
# }
# 
# button:hover {
#     background: #FFA500;
# }
# 
# .result {
#     margin-top: 20px;
#     font-size: 20px;
#     font-weight: bold;
#     padding: 15px;
#     border-radius: 12px;
#     background: rgba(0, 0, 0, 0.4);
# }

# ‚úÖ Kill any running Flask/ngrok processes
!pkill -f flask || echo "No flask running"
!pkill -f ngrok || echo "No ngrok running"

# ‚úÖ Check if port 8000 is occupied
!lsof -i :8000 || echo "Port 8000 is free"

# (Optional) If any PID shows up in the above output, kill it:
!kill -9 4368

# ‚úÖ Run Flask in the background and log output
!nohup python app.py > flask.log 2>&1 &

!tail -n 50 flask.log

# ‚úÖ Start ngrok tunnel
from pyngrok import ngrok, conf
conf.get_default().auth_token = "33pyU8XWfrN8JFX8kwzY8Uf1j7s_612rotnaQX2f58dq3n8Ez"

public_url = ngrok.connect(8000)
print("üåç Public URL:", public_url)

# ‚úÖ Check Flask logs (useful if error happens)
!sleep 3 && tail -n 20 flask.log